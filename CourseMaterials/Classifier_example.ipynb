{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QySjkfwA1hKo"
      },
      "source": [
        "Here, we will use the <a href=\"http://yann.lecun.com/exdb/mnist/\">MNIST hand-written digit dataset</a> to train a classification model. This is a well-established, commonly used dataset consisting of training 60,000 images and 10,000 test images. \n",
        "\n",
        "We will build a perceptron, or neural network, to take images of a hand-written numbers and convert them to a digit.  This is an effective learning exercise because most people have experience trying to read sloppy handwriting; we will build on your intuition and experience to learn how the model works. \n",
        "\n",
        "We start again by loading required modules.  We will use Keras, a versatile user-friendly machine learning library (which is now part of TensorFlow).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6iQql461uTv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cKEAQ-Q2D6K"
      },
      "source": [
        "In this case the three elements of the machine learning model are\n",
        "- Experience/Data/Input: A collection of 28x28 images of hand-written numbers between 0 and 9, with labels\n",
        "- Task: train the model to take an image of a hand-written number and return a label between 0 and 9\n",
        "- Performance/Cost function: We will start with a simple cost function, <i>mse</i>, which minimizes the mean squared error of images that are incorrectly labeled \n",
        "\n",
        "We load the MNIST dataset with the following code and print the shapes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zWD4KQxQ2EOW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape:  (60000, 28, 28)\n",
            "l_train shape:  (60000,)\n",
            "x_test shape:  (10000, 28, 28)\n",
            "l_test shape:  (10000,)\n"
          ]
        }
      ],
      "source": [
        "(x_train, l_train), (x_test, l_test) = mnist.load_data()\n",
        "print('x_train shape: ',x_train.shape)\n",
        "print('l_train shape: ',l_train.shape)\n",
        "print('x_test shape: ',x_test.shape)\n",
        "print('l_test shape: ',l_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This image is a  3\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "index=30\n",
        "print('This image is a ',l_train[index])\n",
        "plt.imshow(x_train[index],cmap='binary_r');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cShn-GZ-2Ebn"
      },
      "source": [
        "The `x` variables have shapes (28,28) which are the black-white pixels for the small images. There are 60,000 training and 10,000 test samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDMFN6Ug3DTJ"
      },
      "source": [
        "Now, we will be dealing with another fully-connected model (using Dense layers). We must now reshape the (28,28) into (28*28) or (784)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B09nmswa2EjR"
      },
      "outputs": [],
      "source": [
        "x_train_new = x_train.reshape(x_train.shape[0],28*28)\n",
        "x_test_new = x_test.reshape(x_test.shape[0],28*28)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4KXFDX62ErG"
      },
      "source": [
        "Next, we will be doing something new. This is a different type of classification problem where we want to predict probability that an image is a 0, a 1, a 2, etc. So we are going to turn the outputs from integers (0-9) into a vector of length 10. If the number is 0, it becomes [1,0,0,0,0,0,0,0,0,0]. If the number is a 1, it becomes [0,1,0,0,0,0,0,0,0,0]. This continues up to 9. We can do this easily using TensorFlow's `to_categorical` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lUOSUASZ2EyO"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "to_categorical() got an unexpected keyword argument 'dtype'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m l_train_new \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m l_test_new \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(l_test, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(l_train_new\u001b[38;5;241m.\u001b[39mshape)\n",
            "\u001b[0;31mTypeError\u001b[0m: to_categorical() got an unexpected keyword argument 'dtype'"
          ]
        }
      ],
      "source": [
        "l_train_new = tf.keras.utils.to_categorical(l_train, num_classes=10, dtype='float32')\n",
        "l_test_new = tf.keras.utils.to_categorical(l_test, num_classes=10, dtype='float32')\n",
        "print(l_train_new.shape)\n",
        "print(l_test_new.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2n18TCh2E4Q"
      },
      "source": [
        "To see this in the data itself, we will look at the first training sample. Print the original label, then the categorical label, then plot the image. Note: we use the `binary_r` colormap which is a grayscale colormap with the lowest values being dark and the highest values being light."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNF1i_8C2E-L"
      },
      "outputs": [],
      "source": [
        "print(l_train[0])\n",
        "print(l_train_new[0])\n",
        "plt.imshow(x_train_new[0].reshape(28,28),cmap='binary_r');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJJLsKmx2FEv"
      },
      "source": [
        "Now we are getting ready to develop our ML model. The last step in data preparation is to normalize our input data. Images have values that range from 0 to 255. Large numbers can cause issues with training since the weights are all initialized to be small. By dividing all values by 255, we get values between 0 and 1. Now, the weights will all be in the general ballpark of where they should be."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgrvTYRR2FLC"
      },
      "outputs": [],
      "source": [
        "x_train_new = x_train_new / 255.\n",
        "x_test_new = x_test_new / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QJ03uto5WpW"
      },
      "source": [
        "We are defining our model as we did with the TensorFlow perceptron. This time, it is slightly more complicated. After the input layer, we have a layer with 256 neurons and a sigmoid activation function. Then we add dropout which helps prevent the model from overfitting to the training data. The rate is the percentage of neurons that are canceled every time the model is run (0.25 = 25%). The second layer has 64 neurons, sigmoid activation, and 10% dropout. The output layer has 10 neurons (for the 10 categories). The softmax activation function is used for classification outputs, because it normalizes the outputs to become probabilities. The sum of all softmax activations will be 1.0 for 100% probability of being one of the outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfmOHhfC5WyX"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(x_train_new.shape[1],)))\n",
        "model.add(Dense(units=256,activation='sigmoid'))\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(Dense(units=64,activation='sigmoid'))\n",
        "model.add(Dropout(rate=0.10))\n",
        "model.add(Dense(units=l_train_new.shape[1],activation='softmax'))\n",
        "model.compile(loss='mse',optimizer='sgd')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhO1Ul1O5W5N"
      },
      "source": [
        "We fit the model to the data for 10 epochs with a larger batch size of 128. We also provide validation data to see how the model does on independent data during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfcTL5lO5W_Y"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train_new,l_train_new,epochs=10,batch_size=128,validation_data=(x_test_new,l_test_new),shuffle=True,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty_42eFK5XEg"
      },
      "source": [
        "With the trained model, we will predict for a random validation sample. Since the prediction will be 10 probabilities, we take the `argmax` or the location in the output with the highest probability to be its prediction. Notice that the model does not perform well. You can keep pressing play to see different predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4Z8hMPA5XJ2"
      },
      "outputs": [],
      "source": [
        "index = np.random.randint(0,x_test_new.shape[0])\n",
        "pred = model.predict(x_test_new[index:index+1])\n",
        "pred_int = np.argmax(pred)\n",
        "print('Truth:',l_test[index],'Prediction:',pred_int,'(confidence=%.2f%%)'%(100*pred[0,pred_int]))\n",
        "plt.imshow(x_test_new[index].reshape(28,28),cmap='binary_r');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV4kGbvm5XQJ"
      },
      "source": [
        "A big issue with the previous model is that it does not have an appropriate loss function and optimizer. We were using the same one from the previous simple problem. However, our data is now 784-dimensional and there are 60,000 training images. This type of classification works better with a binary crossentropy loss function. Also we use a more advanced optimizer called Adam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QthW8aPr5XVH"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(x_train_new.shape[1],)))\n",
        "model.add(Dense(units=256,activation='sigmoid'))\n",
        "model.add(Dropout(rate=0.25))\n",
        "model.add(Dense(units=64,activation='relu'))\n",
        "model.add(Dropout(rate=0.10))\n",
        "model.add(Dense(units=l_train_new.shape[1],activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='Adam')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5AEJz3G5Xbn"
      },
      "source": [
        "We fit the model the same way we did previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_ImlrcF5XhY"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train_new,l_train_new,epochs=10,batch_size=128,validation_data=(x_test_new,l_test_new),shuffle=True,verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US4Q3tmyEIem"
      },
      "source": [
        "We can run the random predictions again to see how much more accurate and confident the model is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAk31UxmEIk6"
      },
      "outputs": [],
      "source": [
        "index = np.random.randint(0,x_test_new.shape[0])\n",
        "pred = model.predict(x_test_new[index:index+1])\n",
        "pred_int = np.argmax(pred)\n",
        "print('Truth:',l_test[index],'Prediction:',pred_int,'(confidence=%.2f%%)'%(100*pred[0,pred_int]))\n",
        "plt.imshow(x_test_new[index].reshape(28,28),cmap='binary_r');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDD7eID0EkOC"
      },
      "source": [
        "For fun, we will add a lot of noise to the image. The standard deviation is about 40%. You can see in the plots that many digits are tough for us to even tell but you may be surprised how well the model works here. Even so, it clearly does not perform as well as it did previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y8V8n4EEkWO"
      },
      "outputs": [],
      "source": [
        "index = np.random.randint(0,x_test_new.shape[0])\n",
        "input_clean = x_test_new[index:index+1]\n",
        "input_noisy = input_clean + np.random.normal(0,0.4,size=[input_clean.shape[1]])\n",
        "pred = model.predict(input_noisy)\n",
        "pred_int = np.argmax(pred)\n",
        "print('Truth:',l_test[index],'Prediction:',pred_int,'(confidence=%.2f%%)'%(100*pred[0,pred_int]))\n",
        "plt.imshow(input_noisy.reshape(28,28),cmap='binary_r',vmin=0,vmax=1);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- What are the hyperparameters in this exercise?  How do they affect performance? \n",
        "- Which are more correlated with speed, and which are more correlated with accuracy? \n",
        "\n",
        "Many of the numbers in this dataset are poorly written - even to the extent that two users may disagree on which number it is! \n",
        "- Would it be fair practice to remove the unclear characters from the set?  How would this improve performance?\n",
        "- How could you use the model's performance to determine which characters are unclear? \n",
        "- The numbers are scaled with white text on a black background. However, most examples of written text are on a white background. Why is the dataset prepared in this manner? \n",
        "- How would you adapt this specific model (28x28 images trained on a black background) for use in the \"real\" world? \n",
        "\n",
        "The dense simply connected perceptron model treats the connection between each pixel exactly the same. In reality, the values of neighboring pixels have more influence than distant pixels. **Convolutional neural networks (CNNs)** use a series of spatial filters to determine the weights of each layer. \n",
        "\n",
        "<a href=\"https://www.aanda.org/articles/aa/pdf/2018/06/aa31344-17.pdf\">*Baso & Ramos* (A&A, 615, A5, 2018)</a> use a CNN to enhance solar magnetic field images. A description of the method, and the code developed for this use, are available in the <a href=\"https://helioml.org/03/Enhancing_SDO_images.html\">Helio-ML online textbook</a>.\n",
        "\n",
        "Another common form of neural network that takes into account connections within neighboring data points is a Long-Short Term Memory (LSTM) network. LSTMs are commonly used on time series data, using past data to predict future behavior. \n",
        "\n",
        "<a href=\"https://www.frontiersin.org/articles/10.3389/fspas.2020.00054/full\">Argall et al. (Front. Astron. Space Sci., Vol. 7, 2020)</a> use an LSTM to detect magnetopause crossings by the Magnetospheric Multscale (MMS) mission. The full code, description and analysis are also available in the <a href=\"https://helioml.org/08/notebook.html\">Helio-ML online textbook</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
